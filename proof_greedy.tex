\section{Proof for Greedy}

Consider a randomized algorithm that samples an arm at time $t$ with probability $x_t \in \Delta_K$. We want an algorithm that satisfies the fairness constraint

\[\forall i \in [K]\;, \; \liminf \frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \right] \geq \lambda_i \;,\]

i.e. all arms $i$ are guaranteed a minimum reward. If an algorithm satisfies this constraint, then we want to minimize the regret, that is defined by in the class of fair algorithms:

\[ \cR_T = \sum_{t=1}^T \bE\left[(x^\star - x_t)^\top\mu \right]\;, \]

where $x^\star$ is one of the (not unique if several arms are optimal) optimal allocation among those that satisfy the constraint. It is more illustrative to write the regret only in terms of the sub-optimal arm. Indeed, for any $i\in [K]$ it holds that $x_i = 1-\sum_{j \neq i } x_j$. Assuming w.l.o.g. that arm $1$ is among the best arms, we obtain that 

\begin{equation}\label{eq::regret}\cR_T =  \sum_{k=2}^K \bE\left[\sum_{t=1}^T (x_{t, i} - x^\star_i)\right] \Delta_k \;, \end{equation}

where $\Delta_k = \mu_k - \mu_1$. This expression is closer to usual formulations of the regret.

Our claim is that this problem can be solved simply by using a greedy algorithm. For that, we first analyze the possible values for $x^\star$. First, it is clear that \[ \mu_k < \mu_1 \Rightarrow x_k^\star = \frac{\lambda_k}{\mu_k} \;. \]

Note that the problem is feasible only if $\sum_{k=1}^{K}\frac{\lambda_i}{\mu_i}=1$. After allocating their probability to sub-optimal arms, any $x^\star$ satisfying \[ \forall j: \mu_j =\mu_1\;, \; x_j^\star \geq \frac{\lambda_j}{\mu_j} \text{ and } \sum_{j: \mu_j=\mu_1} = 1 -\sum_{k: \mu_k<\mu_1} x_k^\star \]

is valid, and is uniquely defined in case $1$ is the only optimal arm or $\sum \frac{\lambda_j}{\mu_j}=1$.

\paragraph{Greedy algorithm} The greedy algorithm simply consists in using the optimal policy corresponding to the empirical estimates of the mean if it provides a feasible allocation. If it's not the case we simply propose uniform sampling. Hence, the steps of the algorithms are: 
\begin{enumerate}
	\item $\forall j$, compute $\wh \mu_j$.
	\item Check if $\sum_{j=1}^K \frac{\lambda_j}{\wh \mu_j}<1$, i.e. if the greedy allocation if feasible.
	\item If yes, use $x_j=\frac{\lambda_j}{\wh \mu_j}$ for each empirically sub-optimal arm, make the probability sum to $1$ by adding the remaining mass on the best empirical arm $\star = \aargmax \wh \mu_j$ (choose at random if several).
\end{enumerate}


\subsection{Analysis}

\paragraph{Fairness constraint} Fix any arm $i \in [K]$. For any sequence of event $E_t$ we obtain that 

\begin{align*} 
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \right] \geq 
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \ind(E_t) \right]\;,
\end{align*}

We define $E_t = \{x_{t,i} \geq \frac{\lambda_i}{\mu_i}-\delta_t, \sum_{i=1}^K \frac{\lambda_i}{\wh \mu_i}\leq 1 \}$, for a sequence of constants $(\delta_t)$. If $E_t$ holds, the algorithm is greedy and we have that 

\begin{align*}  
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \ind(E_t) \right] &\geq \frac{1}{T} \bE\left[\sum_{t=1}^T (\lambda_i - \delta_t \mu_i) \ind(E_t) \right] \\
& \geq  \lambda_i - \frac{1}{T} \sum_{t=1}^T \delta_t \mu_i \bP(E_t) - \frac{1}{T} \sum_{t=1}^T \bP(\bar E_t) \\
& \geq  \lambda_i - \frac{1}{T} \sum_{t=1}^T \delta_t \mu_i - \frac{1}{T} \sum_{t=1}^T  \bP(\bar E_t)\;.
\end{align*}

From this result, we see that our objective will be to optimize $\delta_t$ in order to make both terms small. We now upper bound $\bP(\bar E_t)$ by using the fact that $x_{t,i}\geq \alpha_i \coloneqq \min(\lambda_i, K^{-1})$ depending if the algorithm uses greedy or uniform allocation, and using that $\wh \mu_i\leq 1$. This ensures a number of samples at least of order $\alpha_i t$ for each arm $i$ at each time step $t$. Hence, we further upper bound 

\[\bP(\bar E_t) \leq \bP\left(\bar E_t, \forall j \in [K]:\; N_j(t)\geq \frac{\alpha_j}{2}t\right) + \bP\left(\bar E_t, \exists j \in [K]:\; N_j(t)\leq \frac{\alpha_j}{2}t\right) \;. \]  

We start by upper bounding the second term, 

\begin{align*}
\bP\left(\bar E_t, \forall j \in [K]:\; N_j(t) \leq  \frac{\alpha_j}{2}t\right) \leq \sum_{j=1}^K e^{-t \kl\left(\frac{\alpha_j}{2}, \alpha_j\right)} \;,
\end{align*}

where $\kl$ denotes the Bernoulli KL-divergence, and we used the fact that $N_j(t)$ is stochastically dominated by a sum of i.i.d. Bernoulli random variables with mean $\alpha_j$. We now consider the first term, in which all arms are linearly sampled.

For simplicity, we assume that there $\rho \coloneqq 1- \sum_{i=1}^K \frac{\lambda_i}{\mu_i}>0$, hence the problem is in the interior of the ``feasible set''. Under this assumption, the greedy problem is feasible if for instance \[\frac{\lambda_i}{\wh \mu_i}\leq \frac{\lambda_i}{\mu_i}+ \frac{\rho}{K} \Rightarrow \wh \mu_i \geq \frac{1}{\frac{1}{\mu_i}+\frac{\rho}{K}}=\frac{\mu_i}{1+\frac{\rho \mu_i}{K}}\coloneqq \mu_i - \epsilon_{i, \rho}\;.\]
The probability of this event can be easily controlled with usual union bounds and concentration inequalities as the arms are linearly sampled. 

Finally, if the greedy allocation is feasible we use that
\[x_{t,i} \geq \frac{\lambda_i}{\mu_i} - \delta_t \Rightarrow \wh \mu_{t,i} \leq \frac{\mu_i}{1-\delta_t \mu_i} \coloneqq \mu_i + \epsilon_{i, \delta_t} \;, \]
which is again a large deviation of the empirical mean if $\delta_t$ is large enough. We have that $\epsilon_{i, \delta_t} \approx \delta_t \mu_i^2$, so it is easy to see that $\delta_t$ of the form \[\delta_t = \frac{1}{\mu_i^2} \times \sqrt{\frac{2\gamma \log(t)}{\alpha_i t}}\;,\] 
for some constant $\gamma$, will be enough to do what we want.

\textcolor{red}{I'm going to detail better everything later, in order to exhibit the optimal $\delta_t$ (autant faire les choses bien).}













