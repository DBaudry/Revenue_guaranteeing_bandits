\section{Proof for Greedy}

Consider a randomized algorithm that samples an arm at time $t$ with probability $x_t \in \Delta_K$. We want an algorithm that satisfies the fairness constraint

\[\forall i \in [K]\;, \; \liminf \frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \right] \geq \lambda_i \;,\]

i.e. all arms $i$ are guaranteed a minimum reward. If an algorithm satisfies this constraint, then we want to minimize the regret, that is defined by in the class of fair algorithms:

\[ \cR_T = \sum_{t=1}^T \bE\left[(x^\star - x_t)^\top\mu \right]\;, \]

where $x^\star$ is one of the (not unique if several arms are optimal) optimal allocation among those that satisfy the constraint. It is more illustrative to write the regret only in terms of the sub-optimal arm. Indeed, for any $i\in [K]$ it holds that $x_i = 1-\sum_{j \neq i } x_j$. Assuming w.l.o.g. that arm $1$ is among the best arms, we obtain that 

\begin{equation}\label{eq::regret}\cR_T =  \sum_{k=2}^K \bE\left[\sum_{t=1}^T (x_{t, i} - x^\star_i)\right] \Delta_k \;, \end{equation}

where $\Delta_k = \mu_k - \mu_1$. This expression is closer to usual formulations of the regret.

Our claim is that this problem can be solved simply by using a greedy algorithm. For that, we first analyze the possible values for $x^\star$. First, it is clear that \[ \mu_k < \mu_1 \Rightarrow x_k^\star = \frac{\lambda_k}{\mu_k} \;. \]

Note that the problem is feasible only if $\sum_{k=1}^{k}\frac{\lambda_i}{\mu_i} \leq  1$. after allocating their probability to sub-optimal arms, any $x^\star$ satisfying \[  \forall j > 1,   x_j^\star = \frac{\lambda_j}{\mu_j} \text{ and } x_1^{\star}  = 1 -\sum_{k: \mu_k<\mu_1} x_k^\star \]
Note that the problem is feasible only if $\sum_{k=1}^{K}\frac{\lambda_i}{\mu_i}\leq1$. After allocating their probability to sub-optimal arms, any $x^\star$ satisfying \[ \forall j: \mu_j =\mu_1\;, \; x_j^\star \geq \frac{\lambda_j}{\mu_j} \text{ and } \sum_{j: \mu_j=\mu_1} = 1 -\sum_{k: \mu_k<\mu_1} x_k^\star \]

is valid, and is the unique solution if $1$ is the only optimal arm or $\sum \frac{\lambda_j}{\mu_j}=1$.

\paragraph{Greedy algorithm} The greedy algorithm simply consists in using the optimal policy corresponding to the empirical estimates of the mean if it provides a feasible allocation. If it's not the case we simply propose uniform sampling. Hence, the steps of the algorithms are: 
\begin{enumerate}
	\item $\forall j$, compute $\wh \mu_j$.
	\item Check if $\sum_{j=1}^K \frac{\lambda_j}{\wh \mu_j} \leq  1$, i.e. if the greedy allocation if feasible.
	\item If yes, use $x_j=\frac{\lambda_j}{\wh \mu_j}$ for each empirically sub-optimal arm, make the probability sum to $1$ by adding the remaining mass on the best empirical arm $\star = \aargmax \wh \mu_j$ (choose at random if several).
\end{enumerate}


\subsection{Analysis}

\paragraph{Fairness constraint} Fix any arm $i \in [K]$. For any sequence of events $(E_t)_{t\in[T]}$ we obtain that 

\begin{align*} 
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \right] \geq 
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \ind(E_t) \right]\;.
\end{align*}

For the analysis of Greedy, we define $E_t = \{x_{t,i} \geq \frac{\lambda_i}{\mu_i}-\gamma_t, \sum_{i=1}^K \frac{\lambda_i}{\wh \mu_{t, i}}\leq 1 \}$, for a sequence of constants $(\gamma_t)_{t \in \N}$. If $E_t$ holds, then the greedy allocation is feasible (second event) and we have that 

\begin{align*}  
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \ind(E_t) \right] &\geq \frac{1}{T} \bE\left[\sum_{t=1}^T (\lambda_i - \gamma_t \mu_i) \ind(E_t) \right] \\
& \geq  \lambda_i - \frac{1}{T} \sum_{t=1}^T \gamma_t \mu_i \bP(E_t) - \frac{1}{T} \sum_{t=1}^T \bP(\bar E_t) \\
& \geq  \lambda_i - \frac{\mu_i}{T} \sum_{t=1}^T \gamma_t - \frac{1}{T} \sum_{t=1}^T  \bP(\bar E_t)\;.
\end{align*}

From this result, we see that our objective will be to optimize $\gamma_t$ in order to make both terms small. We now upper bound $\bP(\bar E_t)$ by using the fact that $x_{t,i}\geq \alpha_i \coloneqq \min(\lambda_i, K^{-1})$ depending if the algorithm uses greedy or uniform allocation, and using that $\wh \mu_{t, i}\leq 1$. This ensures a number of samples at least of order $\alpha_i t$ for each arm $i$ at each time step $t$. Hence, we further upper bound 

\[\bP(\bar E_t) \leq \bP\left(\bar E_t, \forall j \in [K]:\; N_j(t)\geq \frac{\alpha_j}{2}t\right) + \bP\left(\bar E_t, \exists j \in [K]:\; N_j(t)\leq \frac{\alpha_j}{2}t\right) \;. \]  

We start by upper bounding the second term,

\begin{align*}
\bP\left(\bar E_t, \exists j \in [K]:\; N_j(t) \leq  \frac{\alpha_j}{2}t\right) \leq \sum_{j=1}^K e^{-t \kl\left(\frac{\alpha_j}{2}, \alpha_j\right)} \leq \sum_{j=1}^K e^{-t \frac{\alpha_j^2}{2}} \;,
\end{align*}

where $\kl$ denotes the Bernoulli KL-divergence, and we used the fact that $N_j(t)$ stochastically dominates a sum of i.i.d. Bernoulli random variables with mean $\alpha_j$. We now consider the first term, in which all arms are linearly sampled.

For simplicity, we assume that $\rho \coloneqq 1- \sum_{i=1}^K \frac{\lambda_i}{\mu_i}>0$, hence the problem is in the interior of the ``feasible set''. Under this assumption, the greedy allocation is feasible if for instance 
\[\frac{\lambda_i}{\wh \mu_i}\leq \frac{\lambda_i}{\mu_i}+ \frac{\rho}{K} \Rightarrow \wh \mu_i \geq \frac{1}{\frac{1}{\mu_i}+\frac{\rho}{K}}=\frac{\mu_i}{1+\frac{\rho \mu_i}{K}} = \mu_{i} - \underbrace{\frac{\mu_i \frac{\rho \mu_i}{K}}{1+\frac{\rho \mu_i}{K}}}_{\epsilon_{i, \rho }} ;.\]

Using Hoeffding's inequality we obtain that 

\begin{align*}
\bP\left(\sum_{i=1}^K \frac{\lambda_i}{\wh \mu_{t, i}}\geq 1, \forall j \in [K]:\; N_j(t)\geq \frac{\alpha_j}{2}t\right) & \leq \sum_{j=1}^K \sum_{n=\alpha_j \frac{t}{2}}^t \bP\left(\wh \mu_{t,j} \leq \mu_j - \epsilon_{j, \rho}\right) \\
& \leq \sum_{j=1}^K \sum_{n=\alpha_j \frac{t}{2}}^t e^{-2n \epsilon_{j, \rho}^2} \;. \\
\end{align*}
So, we obtain that
\begin{equation}\label{eq::feasability_greedy}
\bP\left(\sum_{i=1}^K \frac{\lambda_i}{\wh \mu_{t, i}}\geq 1, \forall j \in [K]:\; N_j(t)\geq \frac{\alpha_j}{2}t\right) \leq \sum_{j=1}^K \frac{e^{-2\alpha_j \frac{t}{2} \epsilon_{j, \rho}^2}}{2\epsilon_{j, \rho}^2} \;.
\end{equation}

To complete the proof it remains to upper bound the term \[P_{t,i} \coloneqq \bP\left(x_{t,i}\leq \frac{\lambda_i}{\mu_i}-\gamma_t, \sum_{i=1}^K \frac{\lambda_i}{\wh \mu_{t, i}}\leq 1, \forall j \in [K]:\; N_j(t)\geq \frac{\alpha_j}{2}t\right) \;.\]

If the greedy allocation is feasible we use that
\[x_{t,i} \geq \frac{\lambda_i}{\mu_i} - \gamma_t \Rightarrow \wh \mu_{t,i} \leq \frac{\mu_i}{1-\gamma_t \mu_i} \coloneqq \mu_i + \epsilon_{i, t}' \;, \]
with $\epsilon_{i, t}'= \gamma_t \frac{\mu_i^2}{1-\gamma_t\mu_i}$. We can then use the same arguments as for the previous term, obtaining that 

\begin{align*}
P_{t,i} &\leq \sum_{n = \alpha_i \frac{t}{2}}^t \bP(\wh \mu_{n,i}\geq \mu_i + \epsilon_{i, t}') \\
& \leq \sum_{n = \alpha_i \frac{t}{2}}^t e^{-2n \epsilon_{i, t}'^2} \leq \sum_{n = \alpha_i \frac{t}{2}}^t e^{-2n (\gamma_t \mu_i^2)^2} \\
& \leq \frac{e^{-\alpha_i t \gamma_t^2 \mu_i^4}}{\gamma_t^2 \mu_i^4}
\end{align*}

We finally combine all these results to obtain the bound 

\begin{align*} 
\frac{1}{T} \bE\left[\sum_{t=1}^T x_{t,i} \mu_i \right] &\geq \lambda_i - \frac{1}{T} \sum_{t=1}^T \left(\mu_i \gamma_t + \frac{e^{-\alpha_i t \gamma_t^2 \mu_i^4}}{\gamma_t^2 \mu_i^4}\right) - \frac{1}{T} \sum_{t=1}^T  \sum_{j=1}^K \left(e^{-t \kl\left(\frac{\alpha_j}{2}, \alpha_j\right)}+ \frac{e^{-\alpha_j t \epsilon_{j, \rho}^2}}{2\epsilon_{j, \rho}^2}\right) \\
& \geq \lambda_i - \frac{1}{T} \sum_{t=1}^T \left(\mu_i \gamma_t + \frac{e^{-\alpha_i t \gamma_t^2 \mu_i^4}}{\gamma_t^2 \mu_i^4}\right) - \frac{1}{T}\sum_{j=1}^K \left(\frac{1}{\kl\left(\frac{\alpha_j}{2}, \alpha_j\right)}+ \frac{1}{2 \alpha_j \epsilon_{j, \rho}^4}\right) \;.
\end{align*}

We now propose a tuning of $\gamma_t = \frac{1}{\mu_i^2}\sqrt{\frac{\log(t)}{\alpha_i t}}$, that provides 

\[\frac{1}{T} \sum_{t=1}^T \left(\mu_i \gamma_t + \frac{e^{-\alpha_i t \gamma_t^2 \mu_i^4}}{\gamma_t^2 \mu_i^4}\right) \leq \frac{1}{T} \sum_{t=1}^T \left(\frac{1}{\mu_i}\sqrt{\frac{\log(t)}{\alpha_i t}} + \sqrt{\frac{\alpha_i}{t \log(t)}}\right) = \cO\left(\sqrt{\frac{\log(T)}{T}}\right) \;. \]

This final step completes the proof. 

\textcolor{red}{Remark: we see a quite big dependency in $\mu_j^{-1}$ through $\epsilon_{k, \rho}^{-4}$. Maybe handling the feasibility constraint differently may avoid this.}

\textcolor{red}{Todo: check how a LCB strat changes the bound. It makes the feasability slightly worse (as all means are inflated). However, it will certainly lower the other terms.}

\textcolor{red}{Todo: Try the rescaling to tackle the case $\rho = 0$. To avoid arbitrarily large values we can truncate the sum (all individual terms should not be greater than $1$).}


\paragraph{Regret} Consider an arm $k$ satisfying $\Delta_k>0$, we want to upper bound $\cR_{T, i} =  \bE\left[\sum_{t=1}^T (x_{t, i} - x^\star_i)\right]$. We can conduct the analysis with the same tools as in the previous section. Indeed, consider the favorable events $\cG_t = \{x_{t,i}-x_i^\star\leq \gamma_t \}$, $\cH_t=\{\forall j \in [K]: \; N_j(t)\geq \alpha_j/2 t \}$ and $\cJ_t = \{\sum_{j=1}^K \frac{\lambda_j}{\wh \mu_{t,j}}\leq 1 \}$. Then we can write that 

\begin{align*}
\cR_{T,i} &= \bE\left[\sum_{t=1}^T (x_{t, i} - x^\star_i)(\ind(\cG_t)+\ind(\bar \cG_t, \cH_t, \cJ_t)+ \ind(\cH_t, \bar \cJ_t)+ \ind(\bar\cH_t))\right] \\
& \leq \sum_{t=1}^T \gamma_t + \bE\left[\sum_{t=1}^T (\ind(\bar \cG_t, \cH_t, \cJ_t)+ \ind(\cH_t, \bar \cJ_t)+ \ind(\bar\cH_t))\right]
\end{align*}

Following Equation~\eqref{eq::linearly_sampled}, we first obtain that 
\[\bE\left[\sum_{t=1}^T \ind(\bar\cH_t)\right] \leq \sum_{j=1}^K \frac{1}{\kl\left(\frac{\alpha_j}{2}, \alpha_j\right)} \;. \]
Similarly, we can use Equation~\eqref{eq::feasability_greedy} to upper bound the term
\[ \bE\left[\sum_{t=1}^T \ind(\cH_t, \bar \cJ_t)\right] \leq \sum_{t=1}^T \sum_{j=1}^K \frac{e^{-2\alpha_j \frac{t}{2} \epsilon_{j, \rho}^2}}{2\epsilon_{j, \rho}^2}\leq \sum_{j=1}^K \frac{1}{2 \alpha_j \epsilon_{j, \rho}^4} \;. \]
It remains to upper bound one term, analogous to $P_{t,i}$ in the fairness analysis. This time, we obtain that if the greedy allocation is feasible then
\[x_{t,i}\geq \frac{\lambda_i}{\mu_i}+ \gamma_t \Rightarrow \wh \mu_{t,i} \leq \frac{\mu_i}{1+\gamma_t \mu_i} \coloneqq \mu_i - \epsilon_{i,t}''\;, \]
with $\epsilon_{i,t}''=\frac{\gamma_t \mu_i^2}{1+\gamma_t \mu_i}$. In the following, we use that $\gamma_t \mu_i \leq 1$ and that under $\cH_t$ it holds that 
\begin{align*}
\bE\left[\sum_{t=1}^T \ind(\bar \cG_t, \cH_t, \cJ_t)\right] &\leq \sum_{t=1}^T \sum_{n=\alpha_i \frac{t}{2}}^t e^{-2\alpha_i n \epsilon_{i,t}''^2} \\
& \leq \sum_{t=1}^T \sum_{n=\alpha_i \frac{t}{2}}^t e^{-2\alpha_i n (\gamma_t \mu_i)^2}\\
& \leq \sum_{t=1}^T \frac{e^{-\alpha_i t (\gamma_t \mu_i)^2}}{2\alpha_i (\gamma_t \mu_i)^2} \;.
\end{align*}

To complete the proof, we choose a tuning of $(\gamma_t)_{t\in[T]}$ to make $\sum_{t=1}^T \left(\gamma_t + \frac{e^{-\alpha_i t (\gamma_t \mu_i)^2}}{2\alpha_i (\gamma_t \mu_i)^2}\right)$ sub-linear. For instance, with $\gamma_t=\frac{1}{\mu_i^2}\sqrt{3\frac{\log(t)}{\alpha_i t}}$ we obtain that 
\begin{align*}\sum_{t=1}^T \left(\gamma_t + \frac{e^{-\alpha_i t (\gamma_t \mu_i)^2}}{2\alpha_i (\gamma_t \mu_i)^2}\right) & \leq \sum_{t=1}^T\frac{1}{\mu_i^2}\sqrt{\frac{3\log(t)}{\alpha_i t}} + \sum_{t=1}^T \frac{1}{2 t^3}\times \sqrt{\frac{t}{3\alpha_i\log(t)}} \\
& = \sum_{t=1}^T\frac{1}{\mu_i^2}\sqrt{\frac{3\log(t)}{\alpha_i t}} + \cO(1)  \\
& = \cO(\sqrt{T\log(T)})
\end{align*}

Combining all these results, we obtain that $\cR_T = \cO(\sqrt{T\log(T)})$ for the greedy algorithm. 

\textcolor{red}{Note: we may try to optimize the constants later. In particular, Equation~\eqref{eq::feasability_greedy} is not very satisfying.}


\textcolor{red}{Some open questions:}

\begin{itemize}
	\item Does a LCB-based algorithm offers a better trade-off between the ``fairness regret'' and the regret? 
	\item The assumptions are $\forall i: \lambda_i>0$, $\exists \rho>0: \sum \frac{\lambda_i}{\mu_i}=1-\rho$. We are interested in allowing $\rho=0$, and allowing $\lambda_i=0$.
	\item Can we provide a lower bound on the regret? (1) in terms of $T$, (2) finding the right dependency in $\mu_i^{-1}$ may be interesting too. 
\end{itemize}

Note: our idea for $\rho=0$ is to replace the uniform sampling by $\frac{x_{t,i}}{\sum x_{t,i}}$ if $\sum x_{t,i}>1$. I feel that it may not be too difficult to analyze. The idea to handle $\lambda_i=0$ would be to simply couple the algorithm with MED. Again, this should be quite trivial though painful to write. We most painful case may be if $\lambda_i=0$ for the optimal arm. With this algorithm we can simply define $\wh x_{t,i}=\max\left\{\frac{\lambda_i}{\wh \mu_{t,i}}, e^{-2N_k(t)\Delta_k(t)^2} \right\}$ for empirically sub-optimal arms and define the feasability condition in an analogous way. Remark: doing this may improve the performance of the algorithm for all instances, it may be interesting to check this empirically.








