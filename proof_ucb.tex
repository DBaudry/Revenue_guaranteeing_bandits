\section{Proof UCB: preference towards no regret}

The algorithm is now the following:
\begin{enumerate}
	\item Compute $\UCB_{k, t} = \wh \mu_{k, t} + B_{k, t}$ for each arm. Typically, $B_{k, t}=C\sqrt{\frac{\log(t)}{N_k(t)}}$ for some $C>0$.
	\item Set $x_{k,t} = \frac{\lambda_k}{\wh \mu_{k, t}}$ if $\sum \frac{\lambda_j}{\wh \mu_{j, t}}<1$, $x_{k, t}=K^{-1}$ otherwise.
	\item To achieve $\sum x_{j, t}=1$, put the remaining mass on $k_t^\star=\aargmax{} \; \UCB_{k, t}$.
\end{enumerate}

Thanks to the last step we can largely use the analysis of the vanilla UCB. Let $(\cG_t)_t$ be the sequence of events defined by 
\[\cG_t = \{\forall k \in [K]\;, \; \UCB_{k, t}\geq \mu_k\} \;. \]

We first write that

\begin{align*}
\cR_{T,k} &= \bE\left[\sum_{t=1}^T (x_{t, k} - x^\star_k)(\ind(\cG_t)+\ind(\bar \cG_t))\right] \\
& \leq \sum_{t=1}^T (1-x_k^\star) \bP(\bar \cG_t) + \bE\left[\sum_{t=1}^T (x_{t,k} - x_k^\star)\ind(\cG_t)\right] \;.
\end{align*}

We upper bound the first term with simple union bounds. If $C>2=$ we have that 
\begin{align*}
\sum_{t=1}^T \bP(\bar \cG_t) &\leq \sum_{t=1}^T \sum_{k=1} \sum_{n=1}^{T}\bP\left(\wh \mu_{k,n}\leq \mu_k - \sqrt{C\frac{\log(t)}{n}}\right) \\
& \sum_{t=1}^T \sum_{k=1} \sum_{n=1}^{t}e^{-2C \log(t)} \\
& \leq K\sum_{t=1}^T \frac{1}{t^{2C-1}}\;,
\end{align*}

which converges if $C>1$. We now consider $\cG_t$. Under this event, all UCBs are optimistic. This event also have a nice implication for our setting, since it makes the allocation $(x_{k,t})$ feasible by assumption. Hence, we either have that $x_{k,t}\leq x_k^\star$ (and the contribution to the regret is $0$), or that $\UCB_{k,t}=\argmax{} \UCB_{j, t}$. We remark that this condition is also the one that would make the vanilla UCB algorithm pull arm $k$. As it holds that $x_{k,t} = \bE[\ind(A_{t+1}=k)|\cF_t]$, we can plug the analysis of the vanilla UCB in our proof as follows,

\begin{align*}
\bE\left[\sum_{t=1}^T \ind(A_{t+1}=k), \UCB_{k, t}\geq \max_j \UCB_{j, t}\right] & \leq \bE\left[\sum_{t=1}^T \ind(A_{t+1}=k, \UCB_{k, t}\geq \UCB_{1, t})\right] \\
& \leq \bE\left[\sum_{t=1}^T \ind(A_{t+1}=k, \UCB_{k, t}\geq \mu_1)\right] \;. \end{align*}

Classically, we then use that for $N_k(t)\geq \frac{2C}{\Delta_k^2} \log(t)$ we have that $\UCB_{k, t}\geq \mu_1 \Rightarrow \wh \mu_{k, t} \geq \mu_k + \frac{\Delta_k}{2}$. This allows us to obtain that 

\begin{align*}
\bE\left[\sum_{t=1}^T \ind(A_{t+1}=k, \UCB_{k, t}\geq \mu_1)\right] &\leq \frac{2C}{\Delta_k^2} \log(T) + \sum_{n=\frac{2C}{\Delta_k^2} \log(T)}^T \bP\left(\wh \mu_{k, n}\geq \mu_k + \frac{\Delta_k}{2}\right) \\
& \leq \frac{2C}{\Delta_k^2} \log(T) + \frac{2}{\Delta_k^2} \;.
\end{align*}

Note that this bound holds for \emph{any} problem instance, including cases where $\lambda_i = 0$ is allowed for any arm $i \in [K]$. In this case, our analysis matches UCB and hence get the $\cO(\log(T))$ problem-dependent bound and a $\cO(\sqrt{T\log(T)})$ worst-case bound.

Interestingly, we can get a constant problem-dependent regret if $\lambda_k>0$. We use again the notation $\alpha_k=\min(\lambda_k, 1/K)$. As in previous section, we upper bound the sum of probabilities that $N_k(t)\leq \alpha_k \frac{t}{2}$ by $\frac{1}{\kl\left(\frac{\alpha_k}{2}, \alpha_k\right)}$. Using the notation \[t_k = \inf\{t\in \N: \; \frac{\alpha_k}{2}t\leq \frac{2C}{\Delta_k^2} \log(t) \}= \cO\left(\frac{4C}{\alpha_k \Delta_k^2}\log\left(\frac{4C}{\alpha_k\Delta_k^2}\right)\right)\;,\]

we now have that 

\begin{align*}
\bE\left[\sum_{t=1}^T \ind(A_{t+1}=k, \UCB_{k, t}\geq \mu_1)\right] &\leq t_k + \frac{1}{\kl\left(\frac{\alpha_k}{2}, \alpha_k\right)} + \frac{2}{\Delta_k^2} \;,
\end{align*}

which scales roughly in $\max\{\alpha_k^{-2}, \alpha_k^{-1}\Delta_k^{-2} \}$, but is a problem-dependent constant. Hence, if $\lambda_k>0$, arm $k$ only contributes to the regret with a constant term 

\[\cR_{T,k}\leq K \sum_{t=1}^T \frac{1}{t^{2C-1}} + t_k + \frac{1}{\kl\left(\frac{\alpha_k}{2}, \alpha_k\right)} + \frac{2}{\Delta_k^2} \;.\]

On the other hand, we have in general that
\[\cR_{T,k}\leq K \sum_{t=1}^T \frac{1}{t^{2C-1}} + \frac{2C}{\Delta_k^2} \log(T) + \frac{2}{\Delta_k^2} \;,  \]
which translates directly in a $\cO(\sqrt{TK\log(T)})$ worst-case bound.

\begin{remark}[Negative problem-dependent regret] 
	
It is easy to see that if we take for instance $2C$ in the confidence bound but keep the analysis with $C$, then the only change in the analysis are (1) the logarithmic term is doubled, (2) $x_{k, t}-x_k^\star\leq \frac{\lambda_k}{\mu_k+\sqrt{C\frac{\log(t)}{N_k(t)}}}-\frac{\lambda_k}{\mu_k}\leq \frac{\lambda_k}{\mu_k+\sqrt{\frac{C}{N_k(t)}}}-\frac{\lambda_k}{\mu_k}$. Using again that $x_{k,t}=\bE[\ind(A_{t+1}=k)|\cF_{t-1}]$ we obtain (with $\cH_t$ being the good event)
\[\bE[\sum_{t=1}^T(x_{k,t}-x_k^\star)\ind(\cH_t)] \leq \sum_{n=1}^T \frac{\lambda_k}{\mu_k+\sqrt{\frac{C}{n}}}-\frac{\lambda_k}{\mu_k} = -\Omega\left(-\frac{\lambda_k}{\mu_k^2}\sqrt{CT}\right)
\]

If we again consider the highly probable event $N_k(t)\geq \alpha_k t/2$, we then have that the term that we upper bounded by $0$ now becomes $-\Omega(\sqrt{T})$. This gives a negative problem-dependent regret asymptotically.
\end{remark}


\begin{remark}[Finer scaling of $N_k(t)$] 
	We used that $N_k(t)\geq \alpha_k t/2$ with high probability since $x_{k, t}\geq \min\{1/K, \lambda_k \}$. We could also use that $x_{k, t}\geq \frac{\lambda_k}{\mu_k+ 2 B_{k, t}}$ with high probability to get a finer result.
\end{remark}